{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training Notebook\n",
        "## Image Colorization using GAN\n",
        "\n",
        "This notebook demonstrates the complete training pipeline for the image colorization model.\n",
        "\n",
        "**Contents:**\n",
        "1. Setup and Configuration\n",
        "2. Data Loading\n",
        "3. Model Initialization\n",
        "4. Training Loop\n",
        "5. Training Visualization\n",
        "6. Model Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# Import from modular structure\n",
        "from src.models import UNetGenerator, PatchDiscriminator\n",
        "from src.preprocessing import create_dataloaders\n",
        "from src.training import Trainer\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"MPS Available: {torch.backends.mps.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Configuration\n",
        "config = {\n",
        "    # Data\n",
        "    'data_dir': '../data/train',\n",
        "    'image_size': 256,\n",
        "    'batch_size': 16,\n",
        "    'val_split': 0.1,\n",
        "    'test_split': 0.1,\n",
        "    'num_workers': 4,\n",
        "    \n",
        "    # Training\n",
        "    'num_epochs': 50,\n",
        "    'lr_g': 2e-4,\n",
        "    'lr_d': 2e-4,\n",
        "    'beta1': 0.5,\n",
        "    'beta2': 0.999,\n",
        "    'l1_lambda': 100,\n",
        "    \n",
        "    # Saving\n",
        "    'save_dir': '../results',\n",
        "    'checkpoint_every': 5,\n",
        "}\n",
        "\n",
        "# Device selection\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"\\nConfiguration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "train_loader, val_loader, test_loader = create_dataloaders(\n",
        "    data_dir=config['data_dir'],\n",
        "    batch_size=config['batch_size'],\n",
        "    image_size=config['image_size'],\n",
        "    val_split=config['val_split'],\n",
        "    test_split=config['test_split'],\n",
        "    num_workers=config['num_workers']\n",
        ")\n",
        "\n",
        "print(f\"\\nData Loaders Created:\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Validation batches: {len(val_loader)}\")\n",
        "print(f\"  Test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize a sample batch\n",
        "L_sample, AB_sample = next(iter(train_loader))\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "fig.suptitle('Sample Training Batch', fontsize=14, fontweight='bold')\n",
        "\n",
        "for i in range(4):\n",
        "    # L channel (grayscale)\n",
        "    axes[0, i].imshow(L_sample[i, 0].numpy(), cmap='gray')\n",
        "    axes[0, i].set_title(f'L Channel {i+1}')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # AB channels (as heatmap)\n",
        "    ab_vis = np.zeros((256, 256, 3))\n",
        "    ab_vis[:, :, 0] = (AB_sample[i, 0].numpy() + 1) / 2  # A -> Red\n",
        "    ab_vis[:, :, 2] = (AB_sample[i, 1].numpy() + 1) / 2  # B -> Blue\n",
        "    axes[1, i].imshow(ab_vis)\n",
        "    axes[1, i].set_title(f'AB Channels {i+1}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"L shape: {L_sample.shape}\")\n",
        "print(f\"AB shape: {AB_sample.shape}\")\n",
        "print(f\"L range: [{L_sample.min():.2f}, {L_sample.max():.2f}]\")\n",
        "print(f\"AB range: [{AB_sample.min():.2f}, {AB_sample.max():.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "generator = UNetGenerator(in_channels=1, out_channels=2, features=64).to(device)\n",
        "discriminator = PatchDiscriminator(in_channels=3, features=64).to(device)\n",
        "\n",
        "# Count parameters\n",
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Model Architecture:\")\n",
        "print(f\"  Generator parameters: {count_params(generator):,}\")\n",
        "print(f\"  Discriminator parameters: {count_params(discriminator):,}\")\n",
        "print(f\"  Total parameters: {count_params(generator) + count_params(discriminator):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test forward pass\n",
        "with torch.no_grad():\n",
        "    L_test = L_sample[:1].to(device)\n",
        "    AB_test = AB_sample[:1].to(device)\n",
        "    \n",
        "    # Generator forward\n",
        "    AB_pred = generator(L_test)\n",
        "    print(f\"Generator input: {L_test.shape}\")\n",
        "    print(f\"Generator output: {AB_pred.shape}\")\n",
        "    \n",
        "    # Discriminator forward\n",
        "    disc_out = discriminator(L_test, AB_pred)\n",
        "    print(f\"Discriminator output: {disc_out.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    generator=generator,\n",
        "    discriminator=discriminator,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    config=config,\n",
        "    save_dir=config['save_dir']\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "history = trainer.train(\n",
        "    num_epochs=config['num_epochs'],\n",
        "    resume_path=None  # Set to checkpoint path to resume training\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "from src.utils import plot_training_history\n",
        "\n",
        "plot_training_history(\n",
        "    history,\n",
        "    save_path='../results/plots/training_history.png',\n",
        "    show=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display training summary\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total Epochs: {len(history['train_g_loss'])}\")\n",
        "print(f\"\")\n",
        "print(f\"Generator Loss:\")\n",
        "print(f\"  Initial: {history['train_g_loss'][0]:.4f}\")\n",
        "print(f\"  Final:   {history['train_g_loss'][-1]:.4f}\")\n",
        "print(f\"  Best:    {min(history['val_g_loss']):.4f}\")\n",
        "print(f\"\")\n",
        "print(f\"Discriminator Loss:\")\n",
        "print(f\"  Initial: {history['train_d_loss'][0]:.4f}\")\n",
        "print(f\"  Final:   {history['train_d_loss'][-1]:.4f}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample predictions after training\n",
        "generator.eval()\n",
        "\n",
        "from src.utils import lab2rgb, denormalize_lab\n",
        "\n",
        "fig, axes = plt.subplots(3, 4, figsize=(14, 10))\n",
        "fig.suptitle('Colorization Results After Training', fontsize=14, fontweight='bold')\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (L, AB_real) in enumerate(test_loader):\n",
        "        if batch_idx >= 1:\n",
        "            break\n",
        "            \n",
        "        L = L.to(device)\n",
        "        AB_pred = generator(L)\n",
        "        \n",
        "        for i in range(min(4, L.size(0))):\n",
        "            L_np = L[i].cpu().numpy().transpose(1, 2, 0)\n",
        "            AB_pred_np = AB_pred[i].cpu().numpy().transpose(1, 2, 0)\n",
        "            AB_real_np = AB_real[i].numpy().transpose(1, 2, 0)\n",
        "            \n",
        "            lab_pred = denormalize_lab(L_np, AB_pred_np)\n",
        "            lab_real = denormalize_lab(L_np, AB_real_np)\n",
        "            \n",
        "            rgb_pred = lab2rgb(lab_pred)\n",
        "            rgb_real = lab2rgb(lab_real)\n",
        "            \n",
        "            # Grayscale\n",
        "            axes[0, i].imshow(L_np.squeeze(), cmap='gray')\n",
        "            axes[0, i].set_title('Grayscale' if i == 0 else '')\n",
        "            axes[0, i].axis('off')\n",
        "            \n",
        "            # Predicted\n",
        "            axes[1, i].imshow(np.clip(rgb_pred, 0, 1))\n",
        "            axes[1, i].set_title('Predicted' if i == 0 else '')\n",
        "            axes[1, i].axis('off')\n",
        "            \n",
        "            # Ground Truth\n",
        "            axes[2, i].imshow(np.clip(rgb_real, 0, 1))\n",
        "            axes[2, i].set_title('Ground Truth' if i == 0 else '')\n",
        "            axes[2, i].axis('off')\n",
        "\n",
        "axes[0, 0].set_ylabel('Input', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Output', fontsize=12)\n",
        "axes[2, 0].set_ylabel('Target', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/plots/training_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save final models\n",
        "os.makedirs('../trained_models', exist_ok=True)\n",
        "\n",
        "torch.save(generator.state_dict(), '../trained_models/generator_final.pth')\n",
        "torch.save(discriminator.state_dict(), '../trained_models/discriminator_final.pth')\n",
        "\n",
        "print(\"Models saved to trained_models/\")\n",
        "print(f\"  - generator_final.pth\")\n",
        "print(f\"  - discriminator_final.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Complete\n",
        "\n",
        "The model has been trained successfully. You can now:\n",
        "1. Run the evaluation notebook (`03_Evaluation.ipynb`) for detailed metrics\n",
        "2. Use the Gradio UI (`python app.py`) for interactive testing\n",
        "3. Use the inference script (`python inference.py`) for batch processing"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
